{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdjLL9gvyVCR"
      },
      "source": [
        "# colab을 이용한 Natural Language Processing(NLP) 실습\n",
        "\n",
        "🎯 학습 목표 : colab 환경에서 NLP 모델 학습 코드를 실행하고 결과를 확인할 수 있다.\n",
        "\n",
        "- 실습 재료\n",
        "\n",
        "| 항목 | 상세 |\n",
        "| ---- | ---- |\n",
        "| 🗂️ 데이터 | 네이버 영화 리뷰 데이터셋 |\n",
        "| 🤖 NLP 언어 모델 | ELECTRA (KoElectra Model) |\n",
        "| 🏗️ NLP 학습 프레임워크 | torch |\n",
        "| 🐍 프로그래밍 언어 | Python |\n",
        "| 👩‍💻 프로그래밍 환경 | Colab |\n",
        "\n",
        "\n",
        "- colab에서 코드 실행 방법은 다음 그림을 참조해주시기 바랍니다.\n",
        "\n",
        "    ![](https://i.imgur.com/0GoFr7q.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. HuggingFace transformers 설치 및 NSMC 데이터셋 다운로드\n",
        "\n",
        "본 실습에서 사용할 학습모델 관련 패키지(Huggingface transformers)와 네이버 영화 리뷰 데이터셋(NSMC)를 다운로드 합니다."
      ],
      "metadata": {
        "id": "wH6EMCkev4KO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc7P9wzHv0LE"
      },
      "source": [
        "!pip install transformers\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다운로드 받은 train 데이터셋과 test 데이터셋의 형식 및 내용을 확인해봅니다."
      ],
      "metadata": {
        "id": "pz4Cf6RvwYyo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q33PkINy4Q2"
      },
      "source": [
        "!head ratings_train.txt\n",
        "!head ratings_test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 필요한 패키지 및 GPU 설정\n",
        "\n",
        "학습에 필요한 패키지를 호출하고, CPU가 아닌 GPU를 사용하도록 설정합니다."
      ],
      "metadata": {
        "id": "UW_wdpCY436z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i7pg7DaGsxp"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "# GPU 사용\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq91g3bGwfeV"
      },
      "source": [
        "# 2. 데이터셋 전처리를 위한 NSMCDataset 클래스 만들기\n",
        "\n",
        "이번 실습에서 사용되는 데이터는 감정분류가 레이블링된 네이버 영화 리뷰 데이터셋를 이용합니다. 이 데이터셋에는 결측치나 중복을 포함하기에 이를 적절히 처리해야 합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZKIQNjZwdn1"
      },
      "source": [
        "class NSMCDataset(Dataset):\n",
        "  # 일부 값중에 NaN이 있음...\n",
        "  def __init__(self, csv_file):\n",
        "    self.dataset = pd.read_csv(csv_file, sep='\\t').dropna(axis=0)\n",
        "    # 중복제거\n",
        "    self.dataset.drop_duplicates(subset=['document'], inplace=True)\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v2-discriminator\")\n",
        "\n",
        "    print(self.dataset.describe())\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.dataset.iloc[idx, 1:3].values\n",
        "    text = row[0]\n",
        "    y = row[1]\n",
        "\n",
        "    inputs = self.tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        pad_to_max_length=True,\n",
        "        add_special_tokens=True\n",
        "        )\n",
        "\n",
        "    input_ids = inputs['input_ids'][0]\n",
        "    attention_mask = inputs['attention_mask'][0]\n",
        "\n",
        "    return input_ids, attention_mask, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESSNkTcXwfUe"
      },
      "source": [
        "train_dataset = NSMCDataset(\"ratings_train.txt\")\n",
        "test_dataset = NSMCDataset(\"ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJiAJPUDz40W"
      },
      "source": [
        "# 3. 모델 다운로드\n",
        "\n",
        "학습을 위한 ELECTRA 모델을 다운로드 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-jRPQXz2r5"
      },
      "source": [
        "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\").to(device)\n",
        "\n",
        "# 한번 실행해보기\n",
        "# text, attention_mask, y = train_dataset[0]\n",
        "# model(text.unsqueeze(0).to(device), attention_mask=attention_mask.unsqueeze(0).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 레이어 보기\n",
        "\n",
        "다운로드 받은 모델의 레이어를 확인합니다."
      ],
      "metadata": {
        "id": "ivVscaYXxNiQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp6x4GHtz46u"
      },
      "source": [
        "# 모델 레이어 보기\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmou0LFl0R_X"
      },
      "source": [
        "# 4. ELECTRA를 활용한 감정 분류 모델 훈련 및 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리를 설치했다면 이제 학습을 위한 설정을 진행합니다.\n",
        "\n",
        "아래 코드를 통하여 감정 분류 작업을 위해 ELECTRA 모델을 미세 조정하는 방법을 배웁니다.\n"
      ],
      "metadata": {
        "id": "p3BK72bj34MH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NpXwESN0Q4h"
      },
      "source": [
        "epochs = 1\n",
        "batch_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzxoo4H274J"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 학습진행\n",
        "\n",
        "설정이 완료되었으면, 학습을 진행합니다.\n",
        "\n",
        "원래는 여러 학습 epoch를 진행해야 하지만, 실습을 간략하게 진행하기 위해 1 epoch와 total 100 batch만으로 학습을 수행합니다."
      ],
      "metadata": {
        "id": "6kwx5gO5-o6O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-BRNeE226HH"
      },
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  total_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  batches = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    y_batch = y_batch.to(device)\n",
        "    y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "    loss = F.cross_entropy(y_pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batches == 100:\n",
        "        print(f\"Batch {batches}\")\n",
        "        break\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    correct += (predicted == y_batch).sum()\n",
        "    total += len(y_batch)\n",
        "\n",
        "    batches += 1\n",
        "    if batches % 100 == 0:\n",
        "      print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
        "\n",
        "  losses.append(total_loss)\n",
        "  accuracies.append(correct.float() / total)\n",
        "  print(\"Train Loss:\", total_loss, \"Accuracy:\", correct.float() / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 과정에서 모델의 학습 데이터셋 loss와 정확도를 확인합니다."
      ],
      "metadata": {
        "id": "_t0QMgRm--U4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQK4R6n4JgVU"
      },
      "source": [
        "losses, accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvEB8g7IFbsD"
      },
      "source": [
        "## 4.2 테스트 데이터셋 정확도 확인하기\n",
        "\n",
        "학습된 모델의 테스트 데이터셋 정확도를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QiALUqm4juf"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "batches = 0\n",
        "\n",
        "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
        "  y_batch = y_batch.to(device)\n",
        "  y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "  _, predicted = torch.max(y_pred, 1)\n",
        "  test_correct += (predicted == y_batch).sum()\n",
        "  test_total += len(y_batch)\n",
        "  if batches == 100:\n",
        "        print(f\"Batch {batches}\")\n",
        "        break\n",
        "  batches += 1\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", test_correct.float() / test_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 모델 저장하기\n",
        "\n",
        "학습과 평가가 완료되었다면, 학습된 모델을 저장합니다."
      ],
      "metadata": {
        "id": "hZhMiyRL_Wcm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcPWEa5U8JZ"
      },
      "source": [
        "torch.save(model.state_dict(), \"model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이상으로 본 실습을 마치도록 하겠습니다.\n",
        "\n",
        "모두들 고생 많으셨습니다!\n",
        "\n",
        "![](https://img.favpng.com/10/1/7/kakaotalk-kakao-friends-emoticon-sticker-png-favpng-mZm2vp0mk2Ce9aTUnBjC4s4DZ.jpg)"
      ],
      "metadata": {
        "id": "nKoKy1Ix4USi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#참고\n",
        "\n",
        "\n",
        "## 사용 Framework : Pytorch + HuggingFace\n",
        "## 사용 Model : KoElectra Model\n",
        "KoElectra-small 사용<br>\n",
        "https://monologg.kr/2020/05/02/koelectra-part1/<br>\n",
        "https://github.com/monologg/KoELECTRA\n",
        "\n",
        "## Dataset\n",
        "네이버 영화 리뷰 데이터셋<br>\n",
        "https://github.com/e9t/nsmc\n",
        "\n",
        "## References\n",
        "- https://huggingface.co/transformers/training.html\n",
        "- https://tutorials.pytorch.kr/beginner/data_loading_tutorial.html\n",
        "- https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html\n",
        "- https://wikidocs.net/44249\n",
        "- https://heegyukim.medium.com/"
      ],
      "metadata": {
        "id": "VwOdT9Wc_fNF"
      }
    }
  ]
}