{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdjLL9gvyVCR"
      },
      "source": [
        "# colabì„ ì´ìš©í•œ Natural Language Processing(NLP) ì‹¤ìŠµ\n",
        "\n",
        "ğŸ¯ í•™ìŠµ ëª©í‘œ : colab í™˜ê²½ì—ì„œ NLP ëª¨ë¸ í•™ìŠµ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "- ì‹¤ìŠµ ì¬ë£Œ\n",
        "\n",
        "| í•­ëª© | ìƒì„¸ |\n",
        "| ---- | ---- |\n",
        "| ğŸ—‚ï¸ ë°ì´í„° | ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹ |\n",
        "| ğŸ¤– NLP ì–¸ì–´ ëª¨ë¸ | ELECTRA (KoElectra Model) |\n",
        "| ğŸ—ï¸ NLP í•™ìŠµ í”„ë ˆì„ì›Œí¬ | torch |\n",
        "| ğŸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ | Python |\n",
        "| ğŸ‘©â€ğŸ’» í”„ë¡œê·¸ë˜ë° í™˜ê²½ | Colab |\n",
        "\n",
        "\n",
        "- colabì—ì„œ ì½”ë“œ ì‹¤í–‰ ë°©ë²•ì€ ë‹¤ìŒ ê·¸ë¦¼ì„ ì°¸ì¡°í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
        "\n",
        "    ![](https://i.imgur.com/0GoFr7q.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. HuggingFace transformers ì„¤ì¹˜ ë° NSMC ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
        "\n",
        "ë³¸ ì‹¤ìŠµì—ì„œ ì‚¬ìš©í•  í•™ìŠµëª¨ë¸ ê´€ë ¨ íŒ¨í‚¤ì§€(Huggingface transformers)ì™€ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹(NSMC)ë¥¼ ë‹¤ìš´ë¡œë“œ í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "wH6EMCkev4KO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc7P9wzHv0LE"
      },
      "source": [
        "!pip install transformers\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë‹¤ìš´ë¡œë“œ ë°›ì€ train ë°ì´í„°ì…‹ê³¼ test ë°ì´í„°ì…‹ì˜ í˜•ì‹ ë° ë‚´ìš©ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "pz4Cf6RvwYyo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q33PkINy4Q2"
      },
      "source": [
        "!head ratings_train.txt\n",
        "!head ratings_test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ë° GPU ì„¤ì •\n",
        "\n",
        "í•™ìŠµì— í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ í˜¸ì¶œí•˜ê³ , CPUê°€ ì•„ë‹Œ GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "UW_wdpCY436z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i7pg7DaGsxp"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "# GPU ì‚¬ìš©\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq91g3bGwfeV"
      },
      "source": [
        "# 2. ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ NSMCDataset í´ë˜ìŠ¤ ë§Œë“¤ê¸°\n",
        "\n",
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ëŠ” ê°ì •ë¶„ë¥˜ê°€ ë ˆì´ë¸”ë§ëœ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹ë¥¼ ì´ìš©í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì—ëŠ” ê²°ì¸¡ì¹˜ë‚˜ ì¤‘ë³µì„ í¬í•¨í•˜ê¸°ì— ì´ë¥¼ ì ì ˆíˆ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZKIQNjZwdn1"
      },
      "source": [
        "class NSMCDataset(Dataset):\n",
        "  # ì¼ë¶€ ê°’ì¤‘ì— NaNì´ ìˆìŒ...\n",
        "  def __init__(self, csv_file):\n",
        "    self.dataset = pd.read_csv(csv_file, sep='\\t').dropna(axis=0)\n",
        "    # ì¤‘ë³µì œê±°\n",
        "    self.dataset.drop_duplicates(subset=['document'], inplace=True)\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v2-discriminator\")\n",
        "\n",
        "    print(self.dataset.describe())\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.dataset.iloc[idx, 1:3].values\n",
        "    text = row[0]\n",
        "    y = row[1]\n",
        "\n",
        "    inputs = self.tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        pad_to_max_length=True,\n",
        "        add_special_tokens=True\n",
        "        )\n",
        "\n",
        "    input_ids = inputs['input_ids'][0]\n",
        "    attention_mask = inputs['attention_mask'][0]\n",
        "\n",
        "    return input_ids, attention_mask, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESSNkTcXwfUe"
      },
      "source": [
        "train_dataset = NSMCDataset(\"ratings_train.txt\")\n",
        "test_dataset = NSMCDataset(\"ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJiAJPUDz40W"
      },
      "source": [
        "# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
        "\n",
        "í•™ìŠµì„ ìœ„í•œ ELECTRA ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-jRPQXz2r5"
      },
      "source": [
        "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\").to(device)\n",
        "\n",
        "# í•œë²ˆ ì‹¤í–‰í•´ë³´ê¸°\n",
        "# text, attention_mask, y = train_dataset[0]\n",
        "# model(text.unsqueeze(0).to(device), attention_mask=attention_mask.unsqueeze(0).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ëª¨ë¸ ë ˆì´ì–´ ë³´ê¸°\n",
        "\n",
        "ë‹¤ìš´ë¡œë“œ ë°›ì€ ëª¨ë¸ì˜ ë ˆì´ì–´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "ivVscaYXxNiQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp6x4GHtz46u"
      },
      "source": [
        "# ëª¨ë¸ ë ˆì´ì–´ ë³´ê¸°\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmou0LFl0R_X"
      },
      "source": [
        "# 4. ELECTRAë¥¼ í™œìš©í•œ ê°ì • ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í–ˆë‹¤ë©´ ì´ì œ í•™ìŠµì„ ìœ„í•œ ì„¤ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ í†µí•˜ì—¬ ê°ì • ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•´ ELECTRA ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n"
      ],
      "metadata": {
        "id": "p3BK72bj34MH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NpXwESN0Q4h"
      },
      "source": [
        "epochs = 1\n",
        "batch_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzxoo4H274J"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 í•™ìŠµì§„í–‰\n",
        "\n",
        "ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìœ¼ë©´, í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì›ë˜ëŠ” ì—¬ëŸ¬ í•™ìŠµ epochë¥¼ ì§„í–‰í•´ì•¼ í•˜ì§€ë§Œ, ì‹¤ìŠµì„ ê°„ëµí•˜ê²Œ ì§„í–‰í•˜ê¸° ìœ„í•´ 1 epochì™€ total 100 batchë§Œìœ¼ë¡œ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "6kwx5gO5-o6O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-BRNeE226HH"
      },
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  total_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  batches = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    y_batch = y_batch.to(device)\n",
        "    y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "    loss = F.cross_entropy(y_pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batches == 100:\n",
        "        print(f\"Batch {batches}\")\n",
        "        break\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    correct += (predicted == y_batch).sum()\n",
        "    total += len(y_batch)\n",
        "\n",
        "    batches += 1\n",
        "    if batches % 100 == 0:\n",
        "      print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
        "\n",
        "  losses.append(total_loss)\n",
        "  accuracies.append(correct.float() / total)\n",
        "  print(\"Train Loss:\", total_loss, \"Accuracy:\", correct.float() / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•™ìŠµ ê³¼ì •ì—ì„œ ëª¨ë¸ì˜ í•™ìŠµ ë°ì´í„°ì…‹ lossì™€ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "_t0QMgRm--U4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQK4R6n4JgVU"
      },
      "source": [
        "losses, accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvEB8g7IFbsD"
      },
      "source": [
        "## 4.2 í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì •í™•ë„ í™•ì¸í•˜ê¸°\n",
        "\n",
        "í•™ìŠµëœ ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì •í™•ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QiALUqm4juf"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "batches = 0\n",
        "\n",
        "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
        "  y_batch = y_batch.to(device)\n",
        "  y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
        "  _, predicted = torch.max(y_pred, 1)\n",
        "  test_correct += (predicted == y_batch).sum()\n",
        "  test_total += len(y_batch)\n",
        "  if batches == 100:\n",
        "        print(f\"Batch {batches}\")\n",
        "        break\n",
        "  batches += 1\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", test_correct.float() / test_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 ëª¨ë¸ ì €ì¥í•˜ê¸°\n",
        "\n",
        "í•™ìŠµê³¼ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆë‹¤ë©´, í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "hZhMiyRL_Wcm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcPWEa5U8JZ"
      },
      "source": [
        "torch.save(model.state_dict(), \"model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ìƒìœ¼ë¡œ ë³¸ ì‹¤ìŠµì„ ë§ˆì¹˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë‘ë“¤ ê³ ìƒ ë§ìœ¼ì…¨ìŠµë‹ˆë‹¤!\n",
        "\n",
        "![](https://img.favpng.com/10/1/7/kakaotalk-kakao-friends-emoticon-sticker-png-favpng-mZm2vp0mk2Ce9aTUnBjC4s4DZ.jpg)"
      ],
      "metadata": {
        "id": "nKoKy1Ix4USi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ì°¸ê³ \n",
        "\n",
        "\n",
        "## ì‚¬ìš© Framework : Pytorch + HuggingFace\n",
        "## ì‚¬ìš© Model : KoElectra Model\n",
        "KoElectra-small ì‚¬ìš©<br>\n",
        "https://monologg.kr/2020/05/02/koelectra-part1/<br>\n",
        "https://github.com/monologg/KoELECTRA\n",
        "\n",
        "## Dataset\n",
        "ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹<br>\n",
        "https://github.com/e9t/nsmc\n",
        "\n",
        "## References\n",
        "- https://huggingface.co/transformers/training.html\n",
        "- https://tutorials.pytorch.kr/beginner/data_loading_tutorial.html\n",
        "- https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html\n",
        "- https://wikidocs.net/44249\n",
        "- https://heegyukim.medium.com/"
      ],
      "metadata": {
        "id": "VwOdT9Wc_fNF"
      }
    }
  ]
}